{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.naive_bayes import MultinomialNB\n\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\nfrom sklearn import metrics\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Additional TFIDF ANALYSIS\nAdditional analysis on the data. Tried KMeans clustering to see what it threw up - Long story short, the clusters seem to tie to genre of the movie and the Location rather than sentiment\n\nAlso, changing the sentiment to just Positive, Negative, Neutral increases the accuracy of baseline model (TFIDF+NB) from 60% to 70%","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/privatetrain/train.tsv', sep='\\t')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby(\"Sentiment\").Sentiment.count().plot.bar(ylim=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Phrase'] = df['Phrase'].str.replace('\\d+', '') # remove digits\ndf['Phrase'] = df['Phrase'].str.replace('[^\\w\\s]', '') # remove punctuation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_stop_words = ENGLISH_STOP_WORDS.union(['film', 'movie', 'cinema', 'theatre', 'hollywood'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(stop_words=my_stop_words, ngram_range=(1, 3))\nvectors = vectorizer.fit_transform(df.Phrase)\nfeature_names = vectorizer.get_feature_names()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"terms = ['']*len(feature_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(terms)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(vectors.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, feature in enumerate(vectorizer.get_feature_names()):\n    terms[i] = feature\n    #print(i, feature)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(vectors)\nprint(terms[25624])\nprint(terms[1503])\nprint(terms[1502])\nprint(vectors[1])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (df.iloc[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def top_tfidf_feats(row, features, top_n=25):\n    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n    topn_ids = np.argsort(row)[::-1][:top_n]\n    top_feats = [(features[i], row[i]) for i in topn_ids]\n    df = pd.DataFrame(top_feats)\n    df.columns = ['feature', 'tfidf']\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_tfidf_feats()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## KMeans Model","metadata":{}},{"cell_type":"code","source":"clusters = 3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = KMeans(n_clusters = clusters, init='k-means++', max_iter=100, n_init=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(vectors)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"centroids = model.cluster_centers_.argsort()[:, ::-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Top terms per cluster:\")\norder_centroids = model.cluster_centers_.argsort()[:, ::-1]\nterms = vectorizer.get_feature_names()\nfor i in range(clusters):\n    print(\"Cluster %d:\" % i),\n    for ind in order_centroids[i, :10]:\n        print(' %s' % terms[ind]),\n    print\n\nprint(\"\\n\")\nprint(\"Prediction\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y = vectorizer.transform([\"started bad got worse\"])\nprediction = model.predict(Y)\nprint(prediction)\n\nY = vectorizer.transform([\"great performance by a great director\"])\nprediction = model.predict(Y)\nprint(prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Naive Bayes","metadata":{}},{"cell_type":"code","source":"df['Sentiment'] = df['Sentiment'].replace(0, 1)\ndf['Sentiment'] = df['Sentiment'].replace(4, 3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby(\"Sentiment\").Sentiment.count().plot.bar(ylim=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df['Phrase'] \ny = df['Sentiment']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_clf_nb_tf = Pipeline([('vect', TfidfVectorizer(stop_words=my_stop_words, ngram_range=(1, 3))), ('clf', MultinomialNB())])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_clf_nb_tf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = [\"uptimately fell flat\"]\n\ntext_clf_nb_tf.predict_proba(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_nb_tf_proba = text_clf_nb_tf.predict_proba(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(predictions_nb_tf_proba)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = []\nnum_grt_80 = 0\nfor i in predictions_nb_tf_proba:\n    for p in i:\n        if p>0.8:\n            num_grt_80 += 1\n            a.append(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(num_grt_80)\n#print(a)\n# 1879 rows out of 51500 with a probability > 90\n# 7863 rows out of 51500 with a probability > 80","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_nb_tf = text_clf_nb_tf.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print a Confusion Matrix\nprint(metrics.confusion_matrix(y_test,predictions_nb_tf))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print a classification report\nprint(metrics.classification_report(y_test,predictions_nb_tf))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the overall accuracy\nprint(metrics.accuracy_score(y_test,predictions_nb_tf))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}